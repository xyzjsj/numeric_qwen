#!/usr/bin/env python3
"""
CIDErè¯„ä¼°è„šæœ¬ - NumericQwen2.5-VLæ¨¡å‹
ç®€å•ç‰ˆæœ¬ï¼Œä¸“æ³¨è§£å†³tokenè®¡æ•°é—®é¢˜
"""

import os
import sys
import json
import torch
import numpy as np
from PIL import Image
from tqdm import tqdm
from typing import List, Dict
from transformers import AutoTokenizer, Qwen2VLForConditionalGeneration, Qwen2VLProcessor
import re
from collections import Counter

# æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾„ï¼Œä»¥ä¾¿å¯¼å…¥æœ¬åœ°æ¨¡å—
sys.path.append('/data1/wangzhiye/1a1a11/original')

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å‹ç»„ä»¶
from numeric_qwen2_5_vl import (
    NumericQwen2_5_VLConfig, 
    NumericQwen2_5_VLForConditionalGeneration, 
    NumericQwen2_5_VLProcessor
)


class CIDErScorer:
    """
    CIDEr (Consensus-based Image Description Evaluation) è¯„åˆ†å™¨
    """
    
    def __init__(self, n: int = 4, sigma: float = 6.0):
        """
        åˆå§‹åŒ–CIDErè¯„åˆ†å™¨
        
        Args:
            n: n-gramçš„æœ€å¤§é•¿åº¦
            sigma: é«˜æ–¯æƒé‡çš„æ ‡å‡†å·®
        """
        self.n = n
        self.sigma = sigma
        self.document_frequency = {}
        
    def compute_cider(self, candidate: str, refs: List[str]) -> float:
        """
        è®¡ç®—å•ä¸ªå€™é€‰ç­”æ¡ˆçš„CIDEråˆ†æ•°
        
        Args:
            candidate: å€™é€‰ç­”æ¡ˆ
            refs: å‚è€ƒç­”æ¡ˆåˆ—è¡¨
            
        Returns:
            CIDEråˆ†æ•°
        """
        score = 0.0
        
        # å¯¹æ¯ä¸ªn-gramçº§åˆ«è®¡ç®—åˆ†æ•°
        for n in range(1, self.n + 1):
            # è·å–å€™é€‰ç­”æ¡ˆçš„n-gram
            candidate_ngrams = self._get_ngrams(candidate, n)
            candidate_counts = Counter(candidate_ngrams)
            
            # è®¡ç®—æ‰€æœ‰å‚è€ƒç­”æ¡ˆçš„n-gram
            ref_ngrams_list = []
            for ref in refs:
                ref_ngrams = self._get_ngrams(ref, n)
                ref_ngrams_list.append(Counter(ref_ngrams))
            
            # è®¡ç®—TF-IDFç›¸ä¼¼åº¦
            similarity = self._compute_tfidf_similarity(
                candidate_counts, ref_ngrams_list, n
            )
            
            # ç´¯åŠ å„çº§n-gramçš„åˆ†æ•°
            score += similarity
        
        # è¿”å›å¹³å‡åˆ†æ•°
        return score / self.n
    
    def _compute_tfidf_similarity(self, candidate_counts: Counter, 
                                  ref_counts_list: List[Counter], n: int) -> float:
        """
        è®¡ç®—TF-IDFç›¸ä¼¼åº¦
        """
        # è®¡ç®—å€™é€‰ç­”æ¡ˆçš„TF-IDFå‘é‡
        candidate_tfidf = self._compute_tfidf_vector(candidate_counts, n)
        
        # è®¡ç®—æ¯ä¸ªå‚è€ƒç­”æ¡ˆçš„TF-IDFå‘é‡
        ref_tfidf_list = []
        for ref_counts in ref_counts_list:
            ref_tfidf = self._compute_tfidf_vector(ref_counts, n)
            ref_tfidf_list.append(ref_tfidf)
        
        # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
        similarities = []
        for ref_tfidf in ref_tfidf_list:
            sim = self._cosine_similarity(candidate_tfidf, ref_tfidf)
            similarities.append(sim)
        
        # è¿”å›ä¸æ‰€æœ‰å‚è€ƒç­”æ¡ˆçš„å¹³å‡ç›¸ä¼¼åº¦
        return np.mean(similarities) if similarities else 0.0
    
    def _compute_tfidf_vector(self, ngram_counts: Counter, n: int) -> Dict[str, float]:
        """
        è®¡ç®—n-gramçš„TF-IDFå‘é‡
        """
        tfidf = {}
        total_ngrams = sum(ngram_counts.values())
        
        if total_ngrams == 0:
            return tfidf
        
        for ngram, count in ngram_counts.items():
            # è®¡ç®—TF (è¯é¢‘)
            tf = count / total_ngrams
            
            # è®¡ç®—IDF (é€†æ–‡æ¡£é¢‘ç‡)
            df = self.document_frequency.get((n, ngram), 1)
            total_docs = self.document_frequency.get(f'total_docs_{n}', 1)
            idf = np.log(total_docs / df)
            
            # è®¡ç®—TF-IDF
            tfidf[ngram] = tf * idf
        
        return tfidf
    
    def _cosine_similarity(self, vec1: Dict[str, float], vec2: Dict[str, float]) -> float:
        """
        è®¡ç®—ä¸¤ä¸ªå‘é‡çš„ä½™å¼¦ç›¸ä¼¼åº¦
        """
        # è·å–å…±åŒçš„è¯æ±‡
        common_words = set(vec1.keys()) & set(vec2.keys())
        
        if not common_words:
            return 0.0
        
        # è®¡ç®—ç‚¹ç§¯
        dot_product = sum(vec1[word] * vec2[word] for word in common_words)
        
        # è®¡ç®—å‘é‡çš„æ¨¡é•¿
        norm1 = np.sqrt(sum(val**2 for val in vec1.values()))
        norm2 = np.sqrt(sum(val**2 for val in vec2.values()))
        
        if norm1 == 0 or norm2 == 0:
            return 0.0
        
        return dot_product / (norm1 * norm2)
    
    def _get_ngrams(self, text: str, n: int) -> List[str]:
        """
        æå–æ–‡æœ¬ä¸­çš„n-gram
        """
        text = self._preprocess_text(text)
        words = text.split()
        
        ngrams = []
        for i in range(len(words) - n + 1):
            ngram = ' '.join(words[i:i+n])
            ngrams.append(ngram)
        
        return ngrams
    
    def _preprocess_text(self, text: str) -> str:
        """
        æ–‡æœ¬é¢„å¤„ç†
        """
        # è½¬å°å†™
        text = text.lower()
        
        # ç§»é™¤æ ‡ç‚¹ç¬¦å·
        text = re.sub(r'[^\w\s]', '', text)
        
        # ç§»é™¤å¤šä½™ç©ºæ ¼
        text = re.sub(r'\s+', ' ', text)
        
        return text.strip()


def test_with_original_qwen():
    """
    ä½¿ç”¨åŸå§‹Qwen2.5-VLæ¨¡å‹è¿›è¡Œæµ‹è¯•ï¼Œçœ‹æ˜¯å¦æ˜¯è‡ªå®šä¹‰æ¨¡å‹çš„é—®é¢˜
    """
    print("ğŸ§ª æµ‹è¯•åŸå§‹Qwen2.5-VLæ¨¡å‹...")
    
    try:
        # å°è¯•åŠ è½½åŸå§‹Qwen2.5-VLæ¨¡å‹
        checkpoint_path = "/data1/wangzhiye/1a1a11/custom_qwen_checkpoint_4250/output/checkpoint-4250"
        
        # ä½¿ç”¨åŸå§‹æ¨¡å‹
        tokenizer = AutoTokenizer.from_pretrained(checkpoint_path, trust_remote_code=True)
        processor = Qwen2VLProcessor.from_pretrained(checkpoint_path)
        model = Qwen2VLForConditionalGeneration.from_pretrained(
            checkpoint_path,
            torch_dtype=torch.bfloat16,
            device_map="auto",
            trust_remote_code=True
        )
        
        print("âœ… åŸå§‹Qwen2.5-VLæ¨¡å‹åŠ è½½æˆåŠŸ")
        return model, processor, tokenizer, "original"
        
    except Exception as e:
        print(f"âš ï¸ åŸå§‹æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        print("ğŸ”„ å›é€€åˆ°è‡ªå®šä¹‰æ¨¡å‹...")
        
        # å›é€€åˆ°è‡ªå®šä¹‰æ¨¡å‹
        tokenizer = AutoTokenizer.from_pretrained(checkpoint_path, trust_remote_code=True)
        processor = NumericQwen2_5_VLProcessor.from_pretrained(checkpoint_path)
        model = NumericQwen2_5_VLForConditionalGeneration.from_pretrained(
            checkpoint_path,
            torch_dtype=torch.bfloat16,
            device_map="auto",
            trust_remote_code=True
        )
        
        print("âœ… è‡ªå®šä¹‰æ¨¡å‹åŠ è½½æˆåŠŸ")
        return model, processor, tokenizer, "custom"


def simple_test_inference(model, processor, tokenizer, model_type):
    """
    ç®€å•çš„æ¨ç†æµ‹è¯•ï¼Œåªæµ‹è¯•ä¸€ä¸ªæ ·æœ¬
    """
    print(f"ğŸ§ª ç®€å•æ¨ç†æµ‹è¯• - {model_type} æ¨¡å‹")
    
    # åŠ è½½æµ‹è¯•æ•°æ®
    test_data_path = "/data1/wangzhiye/LLaMA-Factory/data/1bddx_test_converted1.json"
    with open(test_data_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    image_base_path = "/data1/wangzhiye/LLaMA-Factory/data"
    
    # æµ‹è¯•3ä¸ªæ ·æœ¬
    for i in range(3):
        try:
            sample = data[i]
            print(f"\nğŸ” æµ‹è¯•æ ·æœ¬ {i}:")
            
            # åŠ è½½å›¾åƒ
            image_list = []
            image_paths = sample.get('images', [])[:4]  # é™åˆ¶ä¸º4å¼ 
            
            for img_path in image_paths:
                full_img_path = os.path.join(image_base_path, img_path)
                if os.path.exists(full_img_path):
                    image = Image.open(full_img_path).convert('RGB')
                    image_list.append(image)
            
            # æ„å»ºæ–‡æœ¬
            messages = sample['messages']
            user_messages = [msg for msg in messages if msg.get('role') == 'user']
            if user_messages:
                original_text = user_messages[-1]['content']
                text_without_images = original_text.replace('<image>', '').strip()
                text_prompt = '<|image_pad|>' * len(image_list) + text_without_images
            else:
                text_prompt = '<|image_pad|>' * len(image_list) + "è¯·æè¿°è¿™äº›å›¾ç‰‡ã€‚"
            
            print(f"   å›¾åƒæ•°é‡: {len(image_list)}")
            print(f"   æ–‡æœ¬: {text_prompt[:100]}...")
            
            # å¤„ç†è¾“å…¥
            inputs = processor(
                text=text_prompt,
                images=image_list if image_list else None,
                return_tensors="pt",
                padding=True,
                truncation=True
            )
            
            # ç§»åŠ¨åˆ°è®¾å¤‡
            device = next(model.parameters()).device
            inputs = {k: v.to(device) if isinstance(v, torch.Tensor) else v for k, v in inputs.items()}
            
            print(f"   input_ids shape: {inputs['input_ids'].shape}")
            if 'pixel_values' in inputs:
                print(f"   pixel_values shape: {inputs['pixel_values'].shape}")
            
            # æ£€æŸ¥å›¾åƒtokenæ•°é‡
            input_ids = inputs['input_ids'][0].cpu().numpy()
            image_token_id = 151655  # <|image_pad|> çš„token id
            image_token_count = np.sum(input_ids == image_token_id)
            print(f"   å›¾åƒtokenæ•°é‡: {image_token_count}")
            
            # ç”Ÿæˆ
            with torch.no_grad():
                outputs = model.generate(
                    **inputs,
                    max_new_tokens=50,
                    do_sample=False,
                    pad_token_id=tokenizer.eos_token_id,
                    eos_token_id=tokenizer.eos_token_id,
                    use_cache=False
                )
            
            # è§£ç 
            input_length = inputs['input_ids'].shape[1]
            generated_tokens = outputs[0][input_length:]
            prediction = tokenizer.decode(generated_tokens, skip_special_tokens=True)
            
            print(f"   âœ… é¢„æµ‹: {prediction[:50]}...")
            
        except Exception as e:
            print(f"   âŒ æ ·æœ¬ {i} å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()


def main():
    """
    ä¸»å‡½æ•°
    """
    print("ğŸš€ CIDErè¯„ä¼°å™¨ - è°ƒè¯•ç‰ˆæœ¬")
    print("=" * 60)
    
    # æµ‹è¯•æ¨¡å‹åŠ è½½å’Œæ¨ç†
    model, processor, tokenizer, model_type = test_with_original_qwen()
    
    # ç®€å•æ¨ç†æµ‹è¯•
    simple_test_inference(model, processor, tokenizer, model_type)


if __name__ == "__main__":
    main()
