#!/usr/bin/env python3
"""
æ£€æŸ¥Qwen2.5-VLç‰¹æ®Štokenå’Œæ­£ç¡®çš„promptæ ¼å¼
"""
import os
import torch
from PIL import Image

os.environ["HF_ENDPOINT"] = "https://hf-mirror.com"

# æ·»åŠ æ•°å€¼å¢å¼ºæ¨¡å—è·¯å¾„
import sys
sys.path.append('/data1/wangzhiye/1a1a11/custom_qwen_checkpoint_4250')

from numeric_qwen2_5_vl import NumericQwen2_5_VLForConditionalGeneration, NumericQwen2_5_VLProcessor

def check_special_tokens():
    """æ£€æŸ¥å¤„ç†å™¨çš„ç‰¹æ®Štoken"""
    checkpoint_path = "/data1/wangzhiye/1a1a11/custom_qwen_checkpoint_4250/output/checkpoint-4250"
    
    processor = NumericQwen2_5_VLProcessor.from_pretrained(
        checkpoint_path,
        trust_remote_code=True
    )
    
    print("ğŸ” æ£€æŸ¥ç‰¹æ®ŠToken:")
    tokenizer = processor.tokenizer
    
    # æ£€æŸ¥å…³é”®çš„ç‰¹æ®Štoken
    special_tokens = [
        'vision_start_token', 'vision_end_token', 'image_token', 
        'video_start_token', 'video_end_token', 'eos_token',
        'bos_token', 'pad_token', 'unk_token'
    ]
    
    for token_name in special_tokens:
        if hasattr(tokenizer, token_name):
            token = getattr(tokenizer, token_name)
            print(f"   {token_name}: {token}")
    
    print("\nğŸ“š ç‰¹æ®Štokenæ˜ å°„:")
    if hasattr(tokenizer, 'special_tokens_map'):
        for key, value in tokenizer.special_tokens_map.items():
            print(f"   {key}: {value}")
    
    # æ£€æŸ¥vocabä¸­çš„è§†è§‰ç›¸å…³token
    print("\nğŸ” æœç´¢visionç›¸å…³token:")
    vocab = tokenizer.get_vocab()
    vision_tokens = {k: v for k, v in vocab.items() if 'vision' in k.lower() or 'image' in k.lower()}
    for token, token_id in sorted(vision_tokens.items(), key=lambda x: x[1]):
        print(f"   {token} (ID: {token_id})")

def test_correct_prompt_format():
    """æµ‹è¯•æ­£ç¡®çš„promptæ ¼å¼"""
    checkpoint_path = "/data1/wangzhiye/1a1a11/custom_qwen_checkpoint_4250/output/checkpoint-4250"
    
    processor = NumericQwen2_5_VLProcessor.from_pretrained(
        checkpoint_path,
        trust_remote_code=True
    )
    
    # åˆ›å»ºæµ‹è¯•å›¾åƒ
    image = Image.new('RGB', (224, 224), color='red')
    
    # æµ‹è¯•ä¸åŒçš„promptæ ¼å¼
    prompt_formats = [
        # æ ¼å¼1: åŸºç¡€æ ¼å¼
        "<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>What color is this image?<|im_end|>\n<|im_start|>assistant\n",
        
        # æ ¼å¼2: ä½¿ç”¨image token
        "<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|image|>What color is this image?<|im_end|>\n<|im_start|>assistant\n",
        
        # æ ¼å¼3: ç®€åŒ–æ ¼å¼
        "What color is this image?<|image|>",
        
        # æ ¼å¼4: ä½¿ç”¨vision token
        "<|vision_start|><|image_pad|><|vision_end|>What color is this image?",
    ]
    
    for i, prompt in enumerate(prompt_formats, 1):
        print(f"\nğŸ“‹ æµ‹è¯•æ ¼å¼ {i}: {prompt[:50]}...")
        try:
            # å¤„ç†è¾“å…¥
            inputs = processor(
                text=[prompt],
                images=[image],
                return_tensors="pt"
            )
            
            print(f"   âœ… å¤„ç†æˆåŠŸ")
            print(f"   ğŸ“Š input_ids shape: {inputs.input_ids.shape}")
            if hasattr(inputs, 'pixel_values') and inputs.pixel_values is not None:
                print(f"   ğŸ–¼ï¸ pixel_values shape: {inputs.pixel_values.shape}")
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«å›¾åƒtoken
            input_text = processor.tokenizer.decode(inputs.input_ids[0], skip_special_tokens=False)
            has_vision_tokens = any(token in input_text for token in ['<|vision_start|>', '<|vision_end|>', '<|image_pad|>', '<|image|>'])
            print(f"   ğŸ” åŒ…å«è§†è§‰token: {has_vision_tokens}")
            
            if has_vision_tokens:
                print(f"   ğŸ“ è§£ç çš„æ–‡æœ¬: {input_text}")
            
        except Exception as e:
            print(f"   âŒ å¤„ç†å¤±è´¥: {e}")

if __name__ == "__main__":
    print("ğŸš€ æ£€æŸ¥Qwen2.5-VLç‰¹æ®Štokenå’Œpromptæ ¼å¼")
    print("=" * 60)
    
    check_special_tokens()
    test_correct_prompt_format()
