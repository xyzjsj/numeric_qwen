#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
æœ€ç»ˆå›¾åƒæ¨ç†æµ‹è¯• - ä½¿ç”¨checkpoint-4250
"""

import torch
from PIL import Image
import numpy as np
import os

# æ³¨å†Œè‡ªå®šä¹‰æ¨¡å‹ç»„ä»¶
from numeric_qwen2_5_vl import (
    NumericQwen2_5_VLConfig,
    NumericQwen2_5_VLForConditionalGeneration, 
    NumericQwen2_5_VLProcessor
)

print("ğŸ¯ æœ€ç»ˆå›¾åƒæ¨ç†æµ‹è¯•")
print("=" * 60)

# ä½¿ç”¨checkpoint-4250è·¯å¾„
MODEL_PATH = "/data1/wangzhiye/1a1a11/custom_qwen_checkpoint_4250/output/checkpoint-4250"

def create_simple_test_image():
    """åˆ›å»ºä¸€ä¸ªéå¸¸ç®€å•çš„æµ‹è¯•å›¾åƒ"""
    # åˆ›å»º 224x224 çš„å›¾åƒï¼ŒåŒ…å«ç®€å•çš„å‡ ä½•å›¾å½¢
    image = Image.new('RGB', (224, 224), color='white')
    
    from PIL import ImageDraw
    draw = ImageDraw.Draw(image)
    
    # ç”»ä¸€ä¸ªè“è‰²çŸ©å½¢
    draw.rectangle([50, 50, 150, 100], fill='blue')
    # ç”»ä¸€ä¸ªçº¢è‰²åœ†åœˆ
    draw.ellipse([100, 120, 180, 200], fill='red')
    
    return image

def test_model_basic_functionality():
    """æµ‹è¯•æ¨¡å‹åŸºæœ¬åŠŸèƒ½"""
    try:
        print("ğŸ”§ åŠ è½½æ¨¡å‹è¿›è¡ŒåŸºæœ¬æµ‹è¯•...")
        
        # åªåŠ è½½å¤„ç†å™¨æ¥æµ‹è¯•chat template
        processor = NumericQwen2_5_VLProcessor.from_pretrained(MODEL_PATH)
        print("âœ… å¤„ç†å™¨åŠ è½½æˆåŠŸ")
        
        # æµ‹è¯•chat template
        messages = [
            {"role": "user", "content": "Hello"}
        ]
        
        try:
            text = processor.apply_chat_template(
                messages, tokenize=False, add_generation_prompt=True
            )
            print("âœ… Chat templateå·¥ä½œæ­£å¸¸")
            print(f"Generated text: {text}")
        except Exception as e:
            print(f"âŒ Chat templateå¤±è´¥: {e}")
            return False
        
        return True
        
    except Exception as e:
        print(f"âŒ åŸºæœ¬åŠŸèƒ½æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_image_inference_final():
    """æœ€ç»ˆå›¾åƒæ¨ç†æµ‹è¯•"""
    try:
        print("ğŸ–¼ï¸ å¼€å§‹å›¾åƒæ¨ç†æµ‹è¯•...")
        
        # åŠ è½½å¤„ç†å™¨
        processor = NumericQwen2_5_VLProcessor.from_pretrained(MODEL_PATH)
        print("âœ… å¤„ç†å™¨åŠ è½½æˆåŠŸ")
        
        # åˆ›å»ºæµ‹è¯•å›¾åƒ
        image = create_simple_test_image()
        print("âœ… æµ‹è¯•å›¾åƒåˆ›å»ºæˆåŠŸ")
        
        # æ„å»ºå¯¹è¯
        messages = [
            {
                "role": "user",
                "content": [
                    {
                        "type": "image",
                        "image": image,
                    },
                    {"type": "text", "text": "è¿™ä¸ªå›¾åƒä¸­æœ‰ä»€ä¹ˆé¢œè‰²çš„å½¢çŠ¶ï¼Ÿ"}
                ],
            }
        ]
        
        # åº”ç”¨chat template
        text = processor.apply_chat_template(
            messages, tokenize=False, add_generation_prompt=True
        )
        print("ğŸ“ Chat templateåº”ç”¨æˆåŠŸ")
        
        # å¤„ç†è¾“å…¥ï¼ˆåªå¤„ç†ï¼Œä¸ç”Ÿæˆï¼‰
        print("ğŸ”§ å¤„ç†è¾“å…¥...")
        inputs = processor(
            text=[text],
            images=[image],
            padding=True,
            return_tensors="pt"
        )
        
        print("âœ… è¾“å…¥å¤„ç†æˆåŠŸï¼")
        print(f"è¾“å…¥shape: {inputs.input_ids.shape}")
        print(f"å›¾åƒç‰¹å¾shape: {inputs.pixel_values.shape}")
        
        # æ£€æŸ¥tokenæ•°é‡
        print(f"Tokenæ•°é‡: {inputs.input_ids.shape[1]}")
        
        # ç°åœ¨å°è¯•åŠ è½½æ¨¡å‹å¹¶ç”Ÿæˆ
        print("ğŸš€ åŠ è½½æ¨¡å‹è¿›è¡Œæ¨ç†...")
        model = NumericQwen2_5_VLForConditionalGeneration.from_pretrained(
            MODEL_PATH,
            torch_dtype=torch.float16,
            device_map="auto"
        )
        print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
        
        # ç§»åŠ¨è¾“å…¥åˆ°è®¾å¤‡
        inputs = inputs.to(model.device)
        
        # ç”Ÿæˆ
        print("ğŸ¯ å¼€å§‹ç”Ÿæˆ...")
        with torch.no_grad():
            generated_ids = model.generate(
                **inputs,
                max_new_tokens=64,
                do_sample=True,
                temperature=0.7
            )
        
        # æå–æ–°ç”Ÿæˆçš„tokens
        generated_ids_trimmed = [
            out_ids[len(in_ids):] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)
        ]
        
        # è§£ç è¾“å‡º
        output_text = processor.batch_decode(
            generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False
        )
        
        print("ğŸ‰ å›¾åƒæ¨ç†æˆåŠŸ!")
        print("=" * 40)
        print("ç”Ÿæˆç»“æœ:")
        print(output_text[0])
        print("=" * 40)
        
        return True
        
    except Exception as e:
        print(f"âŒ å›¾åƒæ¨ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    print(f"ä½¿ç”¨æ¨¡å‹è·¯å¾„: {MODEL_PATH}")
    
    # é¦–å…ˆæµ‹è¯•åŸºæœ¬åŠŸèƒ½
    basic_success = test_model_basic_functionality()
    
    if basic_success:
        # å¦‚æœåŸºæœ¬åŠŸèƒ½æ­£å¸¸ï¼Œåˆ™æµ‹è¯•å›¾åƒæ¨ç†
        image_success = test_image_inference_final()
        
        print("\n" + "=" * 60)
        print("ğŸ“‹ æœ€ç»ˆæµ‹è¯•ç»“æœ:")
        print(f"âœ… åŸºæœ¬åŠŸèƒ½: {'æˆåŠŸ' if basic_success else 'å¤±è´¥'}")
        print(f"âœ… å›¾åƒæ¨ç†: {'æˆåŠŸ' if image_success else 'å¤±è´¥'}")
        
        if image_success:
            print("ğŸ‰ æ­å–œï¼æ‚¨çš„checkpoint-4250æ¨¡å‹å¯ä»¥æ­£å¸¸å¤„ç†å›¾åƒï¼")
        else:
            print("âš ï¸ å›¾åƒæ¨ç†ä»æœ‰é—®é¢˜ï¼Œä½†æ¨¡å‹åŸºæœ¬åŠŸèƒ½æ­£å¸¸ã€‚")
    else:
        print("âŒ åŸºæœ¬åŠŸèƒ½æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ¨¡å‹é…ç½®ã€‚")
