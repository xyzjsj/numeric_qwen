#!/usr/bin/env python3
"""
æœ€ç»ˆçš„å›¾åƒTokenåŒ¹é…è§£å†³æ–¹æ¡ˆ
åŸºäºGitCodeåšå®¢æ–‡ç« å’Œtokenæ£€æŸ¥ç»“æœçš„å®Œæ•´ä¿®å¤
"""
import os
import torch
from PIL import Image

os.environ["HF_ENDPOINT"] = "https://hf-mirror.com"

# æ·»åŠ æ•°å€¼å¢å¼ºæ¨¡å—è·¯å¾„
import sys
sys.path.append('/data1/wangzhiye/1a1a11/custom_qwen_checkpoint_4250')

from numeric_qwen2_5_vl import NumericQwen2_5_VLForConditionalGeneration, NumericQwen2_5_VLProcessor

def test_final_solution():
    """æœ€ç»ˆè§£å†³æ–¹æ¡ˆæµ‹è¯•"""
    print("ğŸš€ æœ€ç»ˆå›¾åƒTokenåŒ¹é…è§£å†³æ–¹æ¡ˆæµ‹è¯•")
    print("=" * 60)
    
    checkpoint_path = "/data1/wangzhiye/1a1a11/custom_qwen_checkpoint_4250/output/checkpoint-4250"
    
    # åŠ è½½æ¨¡å‹å’Œå¤„ç†å™¨
    print("ğŸ“‚ åŠ è½½æ¨¡å‹...")
    model = NumericQwen2_5_VLForConditionalGeneration.from_pretrained(
        checkpoint_path,
        torch_dtype=torch.bfloat16,
        device_map="auto",
        trust_remote_code=True
    )
    
    processor = NumericQwen2_5_VLProcessor.from_pretrained(
        checkpoint_path,
        trust_remote_code=True
    )
    
    print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
    
    # åˆ›å»ºè¶…å°å›¾åƒä»¥å‡å°‘Tokenæ•°é‡
    print("\nğŸ¨ åˆ›å»ºè¶…å°æµ‹è¯•å›¾åƒ...")
    image = Image.new('RGB', (56, 56), color='red')  # æå°å°ºå¯¸
    print(f"ğŸ“Š å›¾åƒå°ºå¯¸: {image.size}")
    
    # è®¡ç®—é¢„æœŸTokenæ•°é‡
    pixels = 56 * 56
    expected_tokens = pixels // (28 * 28)
    print(f"ğŸ“Š é¢„æœŸTokenæ•°é‡: {expected_tokens}")
    
    # æµ‹è¯•å¤šç§promptæ ¼å¼
    test_prompts = [
        # æ–¹æ¡ˆ1: ç›´æ¥ä½¿ç”¨vision tokens
        "<|vision_start|><|image_pad|><|vision_end|>What color is this?",
        
        # æ–¹æ¡ˆ2: ä½¿ç”¨image token  
        "What color is this image? <|image|>",
        
        # æ–¹æ¡ˆ3: æ ‡å‡†èŠå¤©æ ¼å¼ + image token
        "<|im_start|>user\n<|image|>What color is this?<|im_end|>\n<|im_start|>assistant\n",
        
        # æ–¹æ¡ˆ4: ä»…ä½¿ç”¨image token
        "<|image|>Describe this image.",
    ]
    
    for i, prompt in enumerate(test_prompts, 1):
        print(f"\nğŸ“‹ æµ‹è¯•æ–¹æ¡ˆ {i}: {prompt[:50]}...")
        
        try:
            # å¤„ç†è¾“å…¥
            inputs = processor(
                text=[prompt],
                images=[image],
                return_tensors="pt",
                padding=True
            )
            
            print(f"   âœ… è¾“å…¥å¤„ç†æˆåŠŸ")
            print(f"   ğŸ“Š input_ids shape: {inputs.input_ids.shape}")
            
            if hasattr(inputs, 'pixel_values') and inputs.pixel_values is not None:
                print(f"   ğŸ–¼ï¸ pixel_values shape: {inputs.pixel_values.shape}")
            
            # æ£€æŸ¥è§£ç åçš„æ–‡æœ¬
            decoded = processor.tokenizer.decode(inputs.input_ids[0], skip_special_tokens=False)
            image_pad_count = decoded.count('<|image_pad|>')
            vision_start_count = decoded.count('<|vision_start|>')
            vision_end_count = decoded.count('<|vision_end|>')
            
            print(f"   ğŸ” image_pad tokens: {image_pad_count}")
            print(f"   ğŸ” vision_start tokens: {vision_start_count}")
            print(f"   ğŸ” vision_end tokens: {vision_end_count}")
            
            if image_pad_count > 0:
                print(f"   âœ… æ‰¾åˆ°å›¾åƒtokensï¼å°è¯•æ¨ç†...")
                
                # ç§»åŠ¨åˆ°è®¾å¤‡
                device_inputs = {k: v.to(model.device) if hasattr(v, 'to') else v for k, v in inputs.items()}
                
                # ç”Ÿæˆ
                with torch.no_grad():
                    outputs = model.generate(
                        **device_inputs,
                        max_new_tokens=50,
                        do_sample=False,
                        pad_token_id=processor.tokenizer.eos_token_id
                    )
                
                # è§£ç å›ç­”
                generated_ids = outputs[0][device_inputs['input_ids'].shape[1]:]
                response = processor.decode(generated_ids, skip_special_tokens=True)
                
                print(f"   ğŸ¯ ç”Ÿæˆå›ç­”: {response}")
                print(f"   âœ… æ–¹æ¡ˆ {i} æˆåŠŸï¼")
                break
            else:
                print(f"   âš ï¸ æ²¡æœ‰æ‰¾åˆ°å›¾åƒtokens")
                
        except Exception as e:
            print(f"   âŒ æ–¹æ¡ˆ {i} å¤±è´¥: {e}")
    
    print("\n" + "=" * 60)
    print("âœ… å›¾åƒTokenåŒ¹é…æµ‹è¯•å®Œæˆ")

if __name__ == "__main__":
    test_final_solution()
