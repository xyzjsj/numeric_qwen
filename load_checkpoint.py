#!/usr/bin/env python3
"""
ä»CheckpointåŠ è½½NumericQwen2.5-VLæ¨¡å‹

ç¤ºä¾‹ç”¨æ³•:
    python load_checkpoint.py
"""

import os
os.environ["HF_ENDPOINT"] = "https://hf-mirror.com"
import json
import torch
from transformers import AutoTokenizer, AutoProcessor
from numeric_qwen2_5_vl import (
    NumericQwen2_5_VLConfig,
    NumericQwen2_5_VLProcessor,
    NumericQwen2_5_VLForConditionalGeneration
)


def load_model_from_checkpoint(checkpoint_path, device="auto"):
    """
    ä»æŒ‡å®šçš„checkpointè·¯å¾„åŠ è½½æ¨¡å‹
    
    Args:
        checkpoint_path: checkpointç›®å½•è·¯å¾„ï¼Œå¦‚ "/data1/wangzhiye/1a1a11/original/output/checkpoint-150"
        device: è®¾å¤‡ç±»å‹ï¼Œé»˜è®¤ä¸º "auto"
    
    Returns:
        model: åŠ è½½çš„æ¨¡å‹
        processor: å¤„ç†å™¨
        tokenizer: åˆ†è¯å™¨
        trainer_state: è®­ç»ƒçŠ¶æ€ä¿¡æ¯
    """
    
    print(f"ğŸ”„ æ­£åœ¨ä» {checkpoint_path} åŠ è½½æ¨¡å‹...")
    
    # æ£€æŸ¥checkpointè·¯å¾„æ˜¯å¦å­˜åœ¨
    if not os.path.exists(checkpoint_path):
        raise FileNotFoundError(f"Checkpointè·¯å¾„ä¸å­˜åœ¨: {checkpoint_path}")
    
    # æ£€æŸ¥å¿…è¦çš„æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    required_files = ["config.json"]
    
    # æ£€æŸ¥é…ç½®æ–‡ä»¶
    for file in required_files:
        file_path = os.path.join(checkpoint_path, file)
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"å¿…éœ€æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
    
    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶ï¼ˆæ”¯æŒå¤šç§æ ¼å¼ï¼‰
    model_file_exists = False
    model_files_found = []
    
    # æ£€æŸ¥å•ä¸ªæ¨¡å‹æ–‡ä»¶
    single_model_files = ["model.safetensors", "pytorch_model.bin"]
    for file in single_model_files:
        file_path = os.path.join(checkpoint_path, file)
        if os.path.exists(file_path):
            model_file_exists = True
            model_files_found.append(file)
            print(f"âœ… æ‰¾åˆ°æ¨¡å‹æ–‡ä»¶: {file}")
    
    # æ£€æŸ¥åˆ†ç‰‡æ¨¡å‹æ–‡ä»¶
    if not model_file_exists:
        # æ£€æŸ¥safetensorsåˆ†ç‰‡æ–‡ä»¶
        files = os.listdir(checkpoint_path)
        safetensors_files = [f for f in files if f.startswith('model-') and f.endswith('.safetensors')]
        pytorch_files = [f for f in files if f.startswith('pytorch_model-') and f.endswith('.bin')]
        
        if safetensors_files:
            model_file_exists = True
            model_files_found.extend(safetensors_files)
            print(f"âœ… æ‰¾åˆ°åˆ†ç‰‡æ¨¡å‹æ–‡ä»¶ (safetensors): {len(safetensors_files)} ä¸ªæ–‡ä»¶")
            # æ£€æŸ¥indexæ–‡ä»¶
            index_file = os.path.join(checkpoint_path, "model.safetensors.index.json")
            if os.path.exists(index_file):
                print(f"âœ… æ‰¾åˆ°æ¨¡å‹ç´¢å¼•æ–‡ä»¶: model.safetensors.index.json")
        elif pytorch_files:
            model_file_exists = True
            model_files_found.extend(pytorch_files)
            print(f"âœ… æ‰¾åˆ°åˆ†ç‰‡æ¨¡å‹æ–‡ä»¶ (pytorch): {len(pytorch_files)} ä¸ªæ–‡ä»¶")
    
    if not model_file_exists:
        available_files = os.listdir(checkpoint_path)
        raise FileNotFoundError(
            f"æœªæ‰¾åˆ°æ¨¡å‹æ–‡ä»¶åœ¨ {checkpoint_path}\n"
            f"æŸ¥æ‰¾çš„æ–‡ä»¶ç±»å‹: model.safetensors, pytorch_model.bin, model-*.safetensors, pytorch_model-*.bin\n"
            f"ç›®å½•ä¸­çš„æ–‡ä»¶: {available_files}"
        )
    
    try:
        # 1. åŠ è½½è®­ç»ƒçŠ¶æ€ä¿¡æ¯ (å¦‚æœå­˜åœ¨)
        trainer_state = None
        trainer_state_path = os.path.join(checkpoint_path, "trainer_state.json")
        if os.path.exists(trainer_state_path):
            print("ğŸ“Š åŠ è½½è®­ç»ƒçŠ¶æ€...")
            with open(trainer_state_path, 'r', encoding='utf-8') as f:
                trainer_state = json.load(f)
            print(f"   å…¨å±€æ­¥æ•°: {trainer_state.get('global_step', 'N/A')}")
            print(f"   è®­ç»ƒè½®æ¬¡: {trainer_state.get('epoch', 'N/A')}")
        
        # 2. åŠ è½½åˆ†è¯å™¨å’Œå¤„ç†å™¨ (ä½¿ç”¨åŸå§‹æ¨¡å‹è·¯å¾„ï¼Œå› ä¸ºcheckpointä¸­å¯èƒ½æ²¡æœ‰)
        base_model_path = "Qwen/Qwen2.5-VL-3B-Instruct"
        print(f"ğŸ”¤ åŠ è½½åˆ†è¯å™¨ä»: {base_model_path}")
        
        try:
            # å°è¯•ä»checkpointåŠ è½½tokenizer
            tokenizer = AutoTokenizer.from_pretrained(checkpoint_path, trust_remote_code=True)
            print("   âœ… ä»checkpointåŠ è½½åˆ†è¯å™¨æˆåŠŸ")
        except:
            # å¦‚æœå¤±è´¥ï¼Œä»åŸºç¡€æ¨¡å‹åŠ è½½
            tokenizer = AutoTokenizer.from_pretrained(base_model_path, trust_remote_code=True)
            print("   âœ… ä»åŸºç¡€æ¨¡å‹åŠ è½½åˆ†è¯å™¨æˆåŠŸ")
        
        print(f"ğŸ–¼ï¸  åŠ è½½å¤„ç†å™¨...")
        processor = None
        try:
            # å°è¯•ä»checkpointåŠ è½½processor
            processor = NumericQwen2_5_VLProcessor.from_pretrained(checkpoint_path)
            print("   âœ… ä»checkpointåŠ è½½å¤„ç†å™¨æˆåŠŸ")
        except Exception as e1:
            print(f"   âš ï¸ checkpointå¤„ç†å™¨åŠ è½½å¤±è´¥: {e1}")
            try:
                # å°è¯•æ‰‹åŠ¨åˆ›å»ºå¤„ç†å™¨ï¼ˆä¸åŒ…å«video_processorï¼‰
                from transformers import Qwen2_5_VLImageProcessor
                
                # åŠ è½½å›¾åƒå¤„ç†å™¨
                image_processor = Qwen2_5_VLImageProcessor.from_pretrained(base_model_path)
                
                # æ‰‹åŠ¨åˆ›å»ºå¤„ç†å™¨ï¼Œè·³è¿‡video_processor
                class SafeNumericProcessor:
                    def __init__(self, image_processor, tokenizer):
                        self.image_processor = image_processor
                        self.tokenizer = tokenizer
                    
                    def __call__(self, text, images=None, **kwargs):
                        # ç®€åŒ–çš„å¤„ç†é€»è¾‘
                        if images is not None:
                            print("   â„¹ï¸ å›¾åƒå¤„ç†æš‚æ—¶è·³è¿‡ï¼ˆå¤„ç†å™¨ç®€åŒ–ç‰ˆæœ¬ï¼‰")
                        
                        # å¤„ç†æ–‡æœ¬è¾“å…¥
                        if isinstance(text, list):
                            text = text[0] if text else ""
                        
                        return self.tokenizer(text, **kwargs)
                
                processor = SafeNumericProcessor(image_processor, tokenizer)
                print("   âœ… åˆ›å»ºç®€åŒ–å¤„ç†å™¨æˆåŠŸï¼ˆæ— è§†é¢‘æ”¯æŒï¼‰")
                
            except Exception as e2:
                print(f"   âš ï¸ ç®€åŒ–å¤„ç†å™¨åˆ›å»ºå¤±è´¥: {e2}")
                print("   â„¹ï¸ å°†ä½¿ç”¨çº¯tokenizeræ¨¡å¼ï¼ˆä»…æ”¯æŒæ–‡æœ¬ï¼‰")
                processor = None
        
        # 3. åŠ è½½æ¨¡å‹é…ç½®
        print("ğŸ“ åŠ è½½æ¨¡å‹é…ç½®...")
        config = NumericQwen2_5_VLConfig.from_pretrained(checkpoint_path)
        print(f"   æ¨¡å‹ç±»å‹: {config.model_type}")
        print(f"   è¯æ±‡è¡¨å¤§å°: {config.vocab_size}")
        if hasattr(config, 'num_token_id'):
            print(f"   æ•°å€¼Token ID: {config.num_token_id}")
        
        # 4. åŠ è½½æ¨¡å‹ (ä»checkpoint)
        print(f"ğŸ¤– åŠ è½½æ¨¡å‹ä»: {checkpoint_path}")
        model = NumericQwen2_5_VLForConditionalGeneration.from_pretrained(
            checkpoint_path,
            config=config,
            torch_dtype=torch.bfloat16,
            device_map=device,
            trust_remote_code=True
        )
        
        # 5. æ¨¡å‹ä¿¡æ¯
        total_params = sum(p.numel() for p in model.parameters())
        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
        
        print(f"âœ… æ¨¡å‹æˆåŠŸåŠ è½½!")
        print(f"ğŸ“Š æ¨¡å‹ä¿¡æ¯:")
        print(f"   æ€»å‚æ•°é‡: {total_params:,} ({total_params/1e9:.2f}B)")
        print(f"   å¯è®­ç»ƒå‚æ•°: {trainable_params:,} ({trainable_params/1e9:.2f}B)")
        print(f"   è®¾å¤‡åˆ†å¸ƒ: {model.hf_device_map if hasattr(model, 'hf_device_map') else 'auto'}")
        
        return model, processor, tokenizer, trainer_state
        
    except Exception as e:
        print(f"âŒ åŠ è½½è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        raise


def test_model_inference(model, processor, tokenizer, test_text="ä½ å¥½ï¼Œè¿™æ˜¯ä¸€ä¸ªæµ‹è¯•ã€‚"):
    """
    æµ‹è¯•æ¨¡å‹æ¨ç†åŠŸèƒ½
    
    Args:
        model: åŠ è½½çš„æ¨¡å‹
        processor: å¤„ç†å™¨
        tokenizer: åˆ†è¯å™¨
        test_text: æµ‹è¯•æ–‡æœ¬
    """
    print(f"\nğŸ§ª æµ‹è¯•æ¨¡å‹æ¨ç†...")
    print(f"è¾“å…¥æ–‡æœ¬: {test_text}")
    
    try:
        # å¤„ç†è¾“å…¥
        if processor is not None:
            try:
                inputs = processor(
                    text=[test_text],
                    images=None,
                    return_tensors="pt",
                    padding=True,
                    truncation=True
                )
                print("   âœ… ä½¿ç”¨processorå¤„ç†è¾“å…¥")
            except Exception as e:
                print(f"   âš ï¸ processorå¤„ç†å¤±è´¥ï¼Œé™çº§ä½¿ç”¨tokenizer: {e}")
                inputs = tokenizer(
                    test_text,
                    return_tensors="pt",
                    padding=True,
                    truncation=True,
                    max_length=512  # é™åˆ¶è¾“å…¥é•¿åº¦
                )
        else:
            # å¦‚æœæ²¡æœ‰processorï¼Œç›´æ¥ä½¿ç”¨tokenizer
            inputs = tokenizer(
                test_text,
                return_tensors="pt",
                padding=True,
                truncation=True,
                max_length=512  # é™åˆ¶è¾“å…¥é•¿åº¦
            )
            print("   âœ… ä½¿ç”¨tokenizerå¤„ç†è¾“å…¥")
        
        # ç§»åŠ¨åˆ°æ¨¡å‹è®¾å¤‡
        device = next(model.parameters()).device
        inputs = {k: v.to(device) if isinstance(v, torch.Tensor) else v for k, v in inputs.items()}
        
        print(f"   è¾“å…¥è®¾å¤‡: {device}")
        print(f"   è¾“å…¥é•¿åº¦: {inputs['input_ids'].shape[1]} tokens")
        
        # æ¨ç† - ä½¿ç”¨æ›´ä¿å®ˆçš„å‚æ•°
        # æ¨ç†
        print("ğŸ”® å¼€å§‹æ¨ç†...")
        with torch.no_grad():
            outputs = model.generate(
                **inputs,
                max_new_tokens=20,
                min_new_tokens=1,
                do_sample=False,
                num_beams=1,
                pad_token_id=tokenizer.eos_token_id,
                eos_token_id=tokenizer.eos_token_id
            )
        
        # è§£ç è¾“å‡º
        input_length = inputs['input_ids'].shape[1]
        generated_tokens = outputs[0][input_length:]
        generated_text = tokenizer.decode(generated_tokens, skip_special_tokens=True)
        
        print(f"âœ… æ¨ç†æˆåŠŸ!")
        print(f"   ç”Ÿæˆé•¿åº¦: {len(generated_tokens)} tokens")
        print(f"   ç”Ÿæˆæ–‡æœ¬: '{generated_text.strip()}'")
        
        # å¦‚æœç”Ÿæˆæ–‡æœ¬ä¸ºç©ºï¼Œç»™å‡ºæç¤º
        if not generated_text.strip():
            print("   â„¹ï¸ ç”Ÿæˆæ–‡æœ¬ä¸ºç©ºï¼Œè¿™å¯èƒ½æ˜¯æ­£å¸¸çš„ï¼ˆæ¨¡å‹è®¤ä¸ºä¸éœ€è¦ç»§ç»­ç”Ÿæˆï¼‰")
        
    except KeyboardInterrupt:
        print("âŒ æ¨ç†è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"âŒ æ¨ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


def continue_training_from_checkpoint(checkpoint_path):
    """
    ä»æ£€æŸ¥ç‚¹ç»§ç»­è®­ç»ƒçš„ç¤ºä¾‹ä»£ç 
    
    Args:
        checkpoint_path: æ£€æŸ¥ç‚¹è·¯å¾„
    """
    print(f"\nğŸ”„ å‡†å¤‡ä» {checkpoint_path} ç»§ç»­è®­ç»ƒ...")
    
    # åŠ è½½æ¨¡å‹
    model, processor, tokenizer, trainer_state = load_model_from_checkpoint(checkpoint_path)
    
    if trainer_state:
        print(f"ğŸ“Š è®­ç»ƒçŠ¶æ€ä¿¡æ¯:")
        print(f"   å½“å‰æ­¥æ•°: {trainer_state.get('global_step', 0)}")
        print(f"   å½“å‰è½®æ¬¡: {trainer_state.get('epoch', 0)}")
        print(f"   æœ€å¤§æ­¥æ•°: {trainer_state.get('max_steps', 'N/A')}")
        print(f"   è®­ç»ƒè½®æ¬¡: {trainer_state.get('num_train_epochs', 'N/A')}")
    
    print("ğŸ’¡ è¦ç»§ç»­è®­ç»ƒï¼Œè¯·åœ¨ train.py ä¸­è®¾ç½®:")
    print(f"   resume_from_checkpoint='{checkpoint_path}'")
    
    return model, processor, tokenizer, trainer_state


def main():
    """
    ä¸»å‡½æ•° - æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨
    """
    print("ğŸš€ NumericQwen2.5-VL CheckpointåŠ è½½å™¨")
    print("=" * 50)
    
    # è®¾ç½®checkpointè·¯å¾„
    checkpoint_path = "/data1/wangzhiye/1a1a11/original/output/checkpoint-150"
    
    try:
        # 1. åŠ è½½æ¨¡å‹
        model, processor, tokenizer, trainer_state = load_model_from_checkpoint(
            checkpoint_path=checkpoint_path,
            device="auto"  # è‡ªåŠ¨åˆ†é…è®¾å¤‡
        )
        
        # 2. æµ‹è¯•æ¨ç† - ä½¿ç”¨ç®€å•çš„æ–‡æœ¬æµ‹è¯•
        test_texts = [
            "ä½ å¥½",
            "è®¡ç®— 2+3=",
            "ä»€ä¹ˆæ˜¯æ•°å­¦ï¼Ÿ"
        ]
        
        for i, test_text in enumerate(test_texts, 1):
            print(f"\nğŸ“ æµ‹è¯• {i}/{len(test_texts)}: {test_text}")
            test_model_inference(
                model=model,
                processor=processor,
                tokenizer=tokenizer,
                test_text=test_text
            )
            
            # å¦‚æœç¬¬ä¸€ä¸ªæµ‹è¯•æˆåŠŸï¼Œç»§ç»­å…¶ä»–æµ‹è¯•
            if i == 1:
                print("   âœ… åŸºç¡€æ¨ç†æµ‹è¯•é€šè¿‡ï¼Œç»§ç»­å…¶ä»–æµ‹è¯•...")
        
        print(f"\nğŸ¯ æµ‹è¯•ç»“è®º:")
        print(f"   - æ¨¡å‹åŠ è½½: âœ… æˆåŠŸ")
        print(f"   - åˆ†è¯å™¨: âœ… æ­£å¸¸")
        print(f"   - å¤„ç†å™¨: {'âœ… æ­£å¸¸' if processor else 'âš ï¸ ç®€åŒ–ç‰ˆæœ¬'}")
        print(f"   - æ¨ç†åŠŸèƒ½: âœ… å¯ç”¨")
        
        # 3. æ˜¾ç¤ºå¦‚ä½•ç»§ç»­è®­ç»ƒ
        print("\n" + "=" * 50)
        print("ğŸ’¡ ç»§ç»­è®­ç»ƒæŒ‡å—:")
        print(f"åœ¨ train.py ä¸­ï¼Œç¡®ä¿ resume_from_checkpoint å‚æ•°è®¾ç½®ä¸º:")
        print(f"'{checkpoint_path}'")
        
        if trainer_state:
            current_step = trainer_state.get('global_step', 0)
            max_steps = trainer_state.get('max_steps', 1338)  # é»˜è®¤å€¼
            progress = (current_step / max_steps) * 100 if max_steps > 0 else 0
            print(f"\nğŸ“ˆ è®­ç»ƒè¿›åº¦: {current_step}/{max_steps} ({progress:.1f}%)")
        
    except Exception as e:
        print(f"âŒ åŠ è½½å¤±è´¥: {e}")
        return False
    
    return True


if __name__ == "__main__":
    # æ£€æŸ¥å¯ç”¨çš„checkpoints
    output_dir = "/data1/wangzhiye/1a1a11/original/output"
    print("ğŸ“ å¯ç”¨çš„æ£€æŸ¥ç‚¹:")
    
    if os.path.exists(output_dir):
        checkpoints = [d for d in os.listdir(output_dir) if d.startswith('checkpoint-')]
        checkpoints.sort(key=lambda x: int(x.split('-')[1]))
        
        for checkpoint in checkpoints:
            checkpoint_path = os.path.join(output_dir, checkpoint)
            # æ£€æŸ¥è®­ç»ƒçŠ¶æ€
            trainer_state_path = os.path.join(checkpoint_path, "trainer_state.json")
            if os.path.exists(trainer_state_path):
                with open(trainer_state_path, 'r') as f:
                    state = json.load(f)
                step = state.get('global_step', 'N/A')
                epoch = state.get('epoch', 'N/A')
                print(f"   âœ… {checkpoint} (æ­¥æ•°: {step}, è½®æ¬¡: {epoch})")
            else:
                print(f"   âš ï¸  {checkpoint} (ç¼ºå°‘trainer_state.json)")
    
    print("\n" + "=" * 50)
    
    # è¿è¡Œä¸»å‡½æ•°
    main()
