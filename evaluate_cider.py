#!/usr/bin/env python3
"""
ä»CheckpointåŠ è½½NumericQwen2.5-VLæ¨¡å‹å¹¶åœ¨æµ‹è¯•é›†ä¸Šè®¡ç®—CIDEråˆ†æ•°

CIDEr (Consensus-based Image Description Evaluation) è¯„ä¼°æ–¹æ³•
è®ºæ–‡: https://arxiv.org/pdf/1411.5726

ä½¿ç”¨æ–¹æ³•:
    python evaluate_cider.py
"""

import os
import json
import torch
import numpy as np
from collections import defaultdict, Counter
import math
import re
from typing import List, Dict, Any
from PIL import Image
from tqdm import tqdm

# å¯¼å…¥æ¨¡å‹ç›¸å…³ç»„ä»¶
from numeric_qwen2_5_vl import (
    NumericQwen2_5_VLConfig,
    NumericQwen2_5_VLProcessor,
    NumericQwen2_5_VLForConditionalGeneration
)
from transformers import AutoTokenizer


class CIDErScorer:
    """
    CIDEråˆ†æ•°è®¡ç®—å™¨
    å®ç°è®ºæ–‡: CIDEr: Consensus-based Image Description Evaluation
    """
    
    def __init__(self, n=4, sigma=6.0):
        """
        åˆå§‹åŒ–CIDErè®¡ç®—å™¨
        
        Args:
            n: n-gramçš„æœ€å¤§é•¿åº¦ (é»˜è®¤4-gram)
            sigma: é«˜æ–¯æ ¸çš„æ ‡å‡†å·® (é»˜è®¤6.0)
        """
        self.n = n
        self.sigma = sigma
        self.document_frequency = defaultdict(float)
        self.ref_len = 0
        
    def cook_refs(self, refs: List[List[str]]):
        """
        é¢„å¤„ç†å‚è€ƒç­”æ¡ˆï¼Œè®¡ç®—æ–‡æ¡£é¢‘ç‡
        
        Args:
            refs: å‚è€ƒç­”æ¡ˆåˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªå›¾åƒçš„å¤šä¸ªå‚è€ƒæè¿°
        """
        print("ğŸ”„ é¢„å¤„ç†å‚è€ƒç­”æ¡ˆ...")
        
        # ç»Ÿè®¡æ‰€æœ‰n-gramçš„æ–‡æ¡£é¢‘ç‡
        for ref_group in tqdm(refs, desc="å¤„ç†å‚è€ƒç­”æ¡ˆ"):
            # å¯¹æ¯ä¸ªå›¾åƒçš„æ‰€æœ‰å‚è€ƒæè¿°
            for ref in ref_group:
                # è·å–æ‰€æœ‰n-gram
                ngrams = self._get_ngrams(ref, self.n)
                # è®¡ç®—è¯¥å‚è€ƒä¸­å‡ºç°çš„å”¯ä¸€n-gram
                unique_ngrams = set(ngrams)
                # ç´¯åŠ æ–‡æ¡£é¢‘ç‡
                for ngram in unique_ngrams:
                    self.document_frequency[ngram] += 1
        
        # è®¡ç®—å‚è€ƒé•¿åº¦ (ç”¨äºé•¿åº¦æƒ©ç½š)
        self.ref_len = np.log(float(len(refs)))
        
        print(f"âœ… é¢„å¤„ç†å®Œæˆï¼Œå…±æ‰¾åˆ° {len(self.document_frequency)} ä¸ªå”¯ä¸€n-gram")
    
    def compute_cider(self, gts: List[List[str]], res: List[str]) -> Dict[str, float]:
        """
        è®¡ç®—CIDEråˆ†æ•°
        
        Args:
            gts: çœŸå®å‚è€ƒç­”æ¡ˆ [[ref1_img1, ref2_img1, ...], [ref1_img2, ...], ...]
            res: ç”Ÿæˆçš„ç­”æ¡ˆ [gen_img1, gen_img2, ...]
            
        Returns:
            åŒ…å«CIDEråˆ†æ•°çš„å­—å…¸
        """
        assert len(gts) == len(res), f"å‚è€ƒç­”æ¡ˆæ•°é‡ {len(gts)} ä¸ç”Ÿæˆç­”æ¡ˆæ•°é‡ {len(res)} ä¸åŒ¹é…"
        
        print(f"ğŸ” è®¡ç®— {len(res)} ä¸ªæ ·æœ¬çš„CIDEråˆ†æ•°...")
        
        # å¦‚æœè¿˜æ²¡æœ‰é¢„å¤„ç†å‚è€ƒç­”æ¡ˆï¼Œå…ˆå¤„ç†
        if not self.document_frequency:
            self.cook_refs(gts)
        
        cider_scores = []
        
        for i, (gt_group, prediction) in enumerate(tqdm(zip(gts, res), total=len(res), desc="è®¡ç®—CIDEr")):
            # è®¡ç®—å•ä¸ªæ ·æœ¬çš„CIDEråˆ†æ•°
            score = self._compute_cider_single(gt_group, prediction)
            cider_scores.append(score)
        
        # è®¡ç®—å¹³å‡åˆ†æ•°
        avg_cider = np.mean(cider_scores)
        
        return {
            'CIDEr': avg_cider,
            'scores': cider_scores,
            'count': len(cider_scores)
        }
    
    def _compute_cider_single(self, refs: List[str], candidate: str) -> float:
        """
        è®¡ç®—å•ä¸ªæ ·æœ¬çš„CIDEråˆ†æ•°
        
        Args:
            refs: è¯¥å›¾åƒçš„æ‰€æœ‰å‚è€ƒæè¿°
            candidate: ç”Ÿæˆçš„æè¿°
            
        Returns:
            CIDEråˆ†æ•°
        """
        score = 0.0
        
        # å¯¹æ¯ä¸ªn-gramçº§åˆ«è®¡ç®—åˆ†æ•°
        for n in range(1, self.n + 1):
            # è·å–å€™é€‰ç­”æ¡ˆçš„n-gram
            candidate_ngrams = self._get_ngrams(candidate, n)
            candidate_counts = Counter(candidate_ngrams)
            
            # è®¡ç®—æ‰€æœ‰å‚è€ƒç­”æ¡ˆçš„n-gram
            ref_ngrams_list = []
            for ref in refs:
                ref_ngrams = self._get_ngrams(ref, n)
                ref_ngrams_list.append(Counter(ref_ngrams))
            
            # è®¡ç®—TF-IDFç›¸ä¼¼åº¦
            similarity = self._compute_tfidf_similarity(
                candidate_counts, ref_ngrams_list, n
            )
            
            # ç´¯åŠ å„çº§n-gramçš„åˆ†æ•°
            score += similarity
        
        # è¿”å›å¹³å‡åˆ†æ•°
        return score / self.n
    
    def _compute_tfidf_similarity(self, candidate_counts: Counter, 
                                  ref_counts_list: List[Counter], n: int) -> float:
        """
        è®¡ç®—TF-IDFç›¸ä¼¼åº¦
        """
        # è®¡ç®—å€™é€‰ç­”æ¡ˆçš„TF-IDFå‘é‡
        candidate_tfidf = self._compute_tfidf_vector(candidate_counts, n)
        
        # è®¡ç®—æ¯ä¸ªå‚è€ƒç­”æ¡ˆçš„TF-IDFå‘é‡
        ref_tfidf_list = []
        for ref_counts in ref_counts_list:
            ref_tfidf = self._compute_tfidf_vector(ref_counts, n)
            ref_tfidf_list.append(ref_tfidf)
        
        # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
        similarities = []
        for ref_tfidf in ref_tfidf_list:
            sim = self._cosine_similarity(candidate_tfidf, ref_tfidf)
            similarities.append(sim)
        
        # è¿”å›ä¸æ‰€æœ‰å‚è€ƒç­”æ¡ˆçš„å¹³å‡ç›¸ä¼¼åº¦
        return np.mean(similarities) if similarities else 0.0
    
    def _compute_tfidf_vector(self, ngram_counts: Counter, n: int) -> Dict[str, float]:
        """
        è®¡ç®—n-gramçš„TF-IDFå‘é‡
        """
        tfidf = {}
        total_ngrams = sum(ngram_counts.values())
        
        if total_ngrams == 0:
            return tfidf
        
        for ngram, count in ngram_counts.items():
            # TF: è¯é¢‘
            tf = count / total_ngrams
            
            # IDF: é€†æ–‡æ¡£é¢‘ç‡
            df = self.document_frequency.get(ngram, 0)
            if df > 0:
                idf = np.log(len(self.document_frequency) / df)
            else:
                idf = 0
            
            # TF-IDF
            tfidf[ngram] = tf * idf
        
        return tfidf
    
    def _cosine_similarity(self, vec1: Dict[str, float], vec2: Dict[str, float]) -> float:
        """
        è®¡ç®—ä¸¤ä¸ªå‘é‡çš„ä½™å¼¦ç›¸ä¼¼åº¦
        """
        # è·å–å…±åŒçš„é”®
        common_keys = set(vec1.keys()) & set(vec2.keys())
        
        if not common_keys:
            return 0.0
        
        # è®¡ç®—ç‚¹ç§¯
        dot_product = sum(vec1[key] * vec2[key] for key in common_keys)
        
        # è®¡ç®—å‘é‡æ¨¡é•¿
        norm1 = math.sqrt(sum(val**2 for val in vec1.values()))
        norm2 = math.sqrt(sum(val**2 for val in vec2.values()))
        
        if norm1 == 0 or norm2 == 0:
            return 0.0
        
        return dot_product / (norm1 * norm2)
    
    def _get_ngrams(self, text: str, n: int) -> List[str]:
        """
        ä»æ–‡æœ¬ä¸­æå–n-gram
        
        Args:
            text: è¾“å…¥æ–‡æœ¬
            n: n-gramçš„é•¿åº¦
            
        Returns:
            n-gramåˆ—è¡¨
        """
        # æ–‡æœ¬é¢„å¤„ç†
        text = self._preprocess_text(text)
        
        # åˆ†è¯
        words = text.split()
        
        # æå–n-gram
        ngrams = []
        for i in range(len(words) - n + 1):
            ngram = ' '.join(words[i:i+n])
            ngrams.append(ngram)
        
        return ngrams
    
    def _preprocess_text(self, text: str) -> str:
        """
        æ–‡æœ¬é¢„å¤„ç†
        """
        # è½¬å°å†™
        text = text.lower()
        
        # ç§»é™¤æ ‡ç‚¹ç¬¦å·
        text = re.sub(r'[^\w\s]', '', text)
        
        # ç§»é™¤å¤šä½™ç©ºæ ¼
        text = re.sub(r'\s+', ' ', text)
        
        return text.strip()


def load_model_from_checkpoint(checkpoint_path: str):
    """
    ä»checkpointåŠ è½½æ¨¡å‹
    """
    print(f"ğŸ”„ ä» {checkpoint_path} åŠ è½½æ¨¡å‹...")
    
    # åŠ è½½åˆ†è¯å™¨
    tokenizer = AutoTokenizer.from_pretrained(checkpoint_path, trust_remote_code=True)
    
    # åŠ è½½å¤„ç†å™¨
    processor = NumericQwen2_5_VLProcessor.from_pretrained(checkpoint_path)
    
    # åŠ è½½æ¨¡å‹
    model = NumericQwen2_5_VLForConditionalGeneration.from_pretrained(
        checkpoint_path,
        torch_dtype=torch.bfloat16,
        device_map="auto",
        trust_remote_code=True
    )
    
    print("âœ… æ¨¡å‹åŠ è½½å®Œæˆ")
    return model, processor, tokenizer


def load_test_dataset(data_path: str):
    """
    åŠ è½½æµ‹è¯•æ•°æ®é›†
    """
    print(f"ğŸ“‚ åŠ è½½æµ‹è¯•æ•°æ®é›†: {data_path}")
    
    with open(data_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    print(f"âœ… åŠ è½½äº† {len(data)} ä¸ªæµ‹è¯•æ ·æœ¬")
    return data


def generate_predictions(model, processor, tokenizer, test_data: List[Dict]):
    """
    ä¸ºæµ‹è¯•æ•°æ®ç”Ÿæˆé¢„æµ‹ç»“æœ
    """
    print(f"ğŸ”® ä¸º {len(test_data)} ä¸ªæ ·æœ¬ç”Ÿæˆé¢„æµ‹...")
    
    predictions = []
    references = []
    
    for i, item in enumerate(tqdm(test_data, desc="ç”Ÿæˆé¢„æµ‹")):
        try:
            # æå–å›¾åƒå’Œå¯¹è¯
            if 'messages' in item:
                messages = item['messages']
                images = item.get('images', [])
            else:
                # å…¼å®¹æ—§æ ¼å¼
                conversations = item.get('conversations', [])
                messages = []
                for turn in conversations:
                    role = turn.get('from', '')
                    content = turn.get('value', '')
                    if role == 'human':
                        messages.append({"role": "user", "content": content})
                    elif role == 'gpt':
                        messages.append({"role": "assistant", "content": content})
                images = [item.get('image')] if item.get('image') else []
            
            # åŠ è½½å›¾åƒ (ä½¿ç”¨æ•°æ®é›†ä¸­çš„å®Œæ•´è·¯å¾„ï¼Œæœ€å¤š4å¼ å›¾ç‰‡)
            image_list = []
            max_images = 4  # è®­ç»ƒæ—¶è®¾ç½®çš„æœ€å¤§å›¾ç‰‡æ•°é‡
            for img_path in images[:max_images]:  # åªå–å‰4å¼ å›¾ç‰‡
                if img_path and os.path.exists(img_path):
                    try:
                        image = Image.open(img_path).convert('RGB')
                        image_list.append(image)
                    except Exception as e:
                        print(f"âš ï¸ åŠ è½½å›¾åƒå¤±è´¥ {img_path}: {e}")
                elif img_path:
                    print(f"âš ï¸ å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {img_path}")
            
            # å¦‚æœåŸå§‹æ ·æœ¬æœ‰è¶…è¿‡4å¼ å›¾ç‰‡ï¼Œç»™å‡ºæç¤º
            if len(images) > max_images:
                print(f"ğŸ“ æ ·æœ¬ {i} æœ‰ {len(images)} å¼ å›¾ç‰‡ï¼Œå·²é™åˆ¶ä¸º {max_images} å¼ ")
            
            # æ„å»ºè¾“å…¥æ–‡æœ¬ (ä½¿ç”¨èŠå¤©æ¨¡æ¿æ ¼å¼)
            user_messages = [msg for msg in messages if msg.get('role') == 'user']
            if user_messages:
                original_text = user_messages[-1]['content']  # ä½¿ç”¨æœ€åä¸€ä¸ªç”¨æˆ·æ¶ˆæ¯
                
                # æ‰“å°è°ƒè¯•ä¿¡æ¯
                print(f"ğŸ” æ ·æœ¬ {i} åŸå§‹è¾“å…¥: {str(original_text)[:100]}...")
                print(f"ğŸ” æ ·æœ¬ {i} å›¾ç‰‡æ•°é‡: {len(image_list)}")
                
                # å¦‚æœæœ‰å›¾åƒï¼Œæ„å»ºconversationæ ¼å¼çš„æ¶ˆæ¯
                if image_list:
                    # ç¡®ä¿original_textæ˜¯å­—ç¬¦ä¸²
                    if isinstance(original_text, str):
                        # ç§»é™¤åŸæœ‰çš„æ‰€æœ‰<image>æ ‡è®°
                        cleaned_text = original_text.replace('<image>', '').strip()
                    else:
                        # å¦‚æœä¸æ˜¯å­—ç¬¦ä¸²ï¼Œè½¬æ¢ä¸ºå­—ç¬¦ä¸²
                        cleaned_text = str(original_text)
                    
                    # æ„å»ºæ ‡å‡†çš„conversationæ ¼å¼
                    content_parts = []
                    # ä¸ºæ¯ä¸ªå›¾åƒæ·»åŠ å›¾åƒéƒ¨åˆ†
                    for _ in image_list:
                        content_parts.append({"type": "image"})
                    # æ·»åŠ æ–‡æœ¬éƒ¨åˆ†
                    if cleaned_text:
                        content_parts.append({"type": "text", "text": cleaned_text})
                    
                    conversation = [
                        {
                            "role": "user",
                            "content": content_parts
                        }
                    ]
                    
                    print(f"ğŸ” æ ·æœ¬ {i} conversationæ ¼å¼: {conversation}")
                else:
                    # ç¡®ä¿original_textæ˜¯å­—ç¬¦ä¸²
                    text_content = str(original_text) if not isinstance(original_text, str) else original_text
                    conversation = [
                        {
                            "role": "user",
                            "content": [{"type": "text", "text": text_content}]
                        }
                    ]
            else:
                if image_list:
                    content_parts = []
                    for _ in image_list:
                        content_parts.append({"type": "image"})
                    content_parts.append({"type": "text", "text": "è¯·æè¿°è¿™äº›å›¾ç‰‡ã€‚"})
                    
                    conversation = [
                        {
                            "role": "user",
                            "content": content_parts
                        }
                    ]
                else:
                    conversation = [
                        {
                            "role": "user",
                            "content": [{"type": "text", "text": "è¯·æè¿°è¿™å¼ å›¾ç‰‡ã€‚"}]
                        }
                    ]
            
            # å¤„ç†è¾“å…¥ - æ‰‹åŠ¨æ„å»ºæ–‡æœ¬æ ¼å¼
            if image_list:
                # æ–¹æ³•: æ‰‹åŠ¨æ„å»ºæ–‡æœ¬ï¼Œç¡®ä¿å›¾åƒtokenæ­£ç¡®
                text_parts = []
                for content_item in conversation[0]['content']:
                    if content_item['type'] == 'image':
                        text_parts.append('<image>')
                    else:
                        text_parts.append(content_item['text'])
                text_prompt = ''.join(text_parts)
                print(f"ğŸ” æ ·æœ¬ {i} æ‰‹åŠ¨æ„å»ºæ–‡æœ¬: {text_prompt[:200]}...")
                
                # éªŒè¯å›¾åƒtokenæ•°é‡
                image_token_count = text_prompt.count('<image>')
                print(f"ğŸ” æ ·æœ¬ {i} å›¾åƒtokenæ•°é‡: {image_token_count}, å›¾åƒæ•°é‡: {len(image_list)}")
                
                if image_token_count != len(image_list):
                    print(f"âš ï¸ å›¾åƒtokenæ•°é‡ä¸åŒ¹é…ï¼Œè°ƒæ•´ä¸­...")
                    # ç§»é™¤æ‰€æœ‰ç°æœ‰çš„<image>æ ‡è®°å¹¶é‡æ–°æ·»åŠ æ­£ç¡®æ•°é‡çš„æ ‡è®°
                    text_without_images = text_prompt.replace('<image>', '')
                    image_tokens = '<image>' * len(image_list)
                    text_prompt = image_tokens + text_without_images
                    print(f"ğŸ”§ ä¿®æ­£åçš„æ–‡æœ¬: {text_prompt[:200]}...")
                
                inputs = processor(
                    text=text_prompt,  # ä¼ å…¥å¤„ç†åçš„å­—ç¬¦ä¸²
                    images=image_list,
                    return_tensors="pt",
                    padding=True,
                    truncation=True
                )
                
                # è°ƒè¯•ï¼šæ‰“å°å¤„ç†åçš„input_ids
                print(f"ğŸ” æ ·æœ¬ {i} å¤„ç†å™¨å¤„ç†åçš„input_ids shape: {inputs['input_ids'].shape}")
                if 'pixel_values' in inputs:
                    print(f"ğŸ” æ ·æœ¬ {i} pixel_values shape: {inputs['pixel_values'].shape}")
                
            else:
                # å¯¹äºæ— å›¾åƒæƒ…å†µï¼Œä½¿ç”¨ç®€å•æ–‡æœ¬
                text_content = conversation[0]['content'][0]['text']
                
                inputs = processor(
                    text=text_content,
                    images=None,
                    return_tensors="pt",
                    padding=True,
                    truncation=True
                )
            
            # ç§»åŠ¨åˆ°æ¨¡å‹è®¾å¤‡
            device = next(model.parameters()).device
            inputs = {k: v.to(device) if isinstance(v, torch.Tensor) else v for k, v in inputs.items()}
            
            # ç”Ÿæˆé¢„æµ‹
            with torch.no_grad():
                outputs = model.generate(
                    **inputs,
                    max_new_tokens=100,
                    do_sample=False,
                    pad_token_id=tokenizer.eos_token_id,
                    eos_token_id=tokenizer.eos_token_id
                )
            
            # è§£ç ç”Ÿæˆçš„æ–‡æœ¬
            input_length = inputs['input_ids'].shape[1]
            generated_tokens = outputs[0][input_length:]
            prediction = tokenizer.decode(generated_tokens, skip_special_tokens=True)
            
            predictions.append(prediction)
            
            # æå–å‚è€ƒç­”æ¡ˆ
            assistant_messages = [msg for msg in messages if msg.get('role') == 'assistant']
            ref_texts = [msg['content'] for msg in assistant_messages]
            if not ref_texts:
                ref_texts = [""]  # å¦‚æœæ²¡æœ‰å‚è€ƒç­”æ¡ˆï¼Œä½¿ç”¨ç©ºå­—ç¬¦ä¸²
            
            references.append(ref_texts)
            
        except Exception as e:
            print(f"âš ï¸ å¤„ç†æ ·æœ¬ {i} æ—¶å‡ºé”™: {e}")
            import traceback
            print(f"ğŸ” è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
            traceback.print_exc()
            predictions.append("")
            references.append([""])
    
    return predictions, references


def main():
    """
    ä¸»å‡½æ•°
    """
    print("ğŸš€ CIDErè¯„ä¼°å™¨ - NumericQwen2.5-VL")
    print("=" * 60)
    
    # é…ç½®è·¯å¾„
    checkpoint_path = "/data1/wangzhiye/1a1a11/original/output/checkpoint-200"
    test_data_path = "/data1/wangzhiye/LLaMA-Factory/data/1bddx_test_converted1.json"
    
    try:
        # 1. åŠ è½½æ¨¡å‹
        model, processor, tokenizer = load_model_from_checkpoint(checkpoint_path)
        
        # 2. åŠ è½½æµ‹è¯•æ•°æ® (åªæµ‹è¯•å‰3ä¸ªæ ·æœ¬)
        test_data = load_test_dataset(test_data_path)[:3]
        
        # 3. ç”Ÿæˆé¢„æµ‹ (ä½¿ç”¨æ•°æ®é›†ä¸­çš„å®Œæ•´å›¾ç‰‡è·¯å¾„)
        predictions, references = generate_predictions(
            model, processor, tokenizer, test_data
        )
        
        # 4. è®¡ç®—CIDEråˆ†æ•°
        print("\n" + "=" * 60)
        print("ğŸ“Š è®¡ç®—CIDEråˆ†æ•°...")
        
        cider_scorer = CIDErScorer(n=4, sigma=6.0)
        results = cider_scorer.compute_cider(references, predictions)
        
        # 5. æ˜¾ç¤ºç»“æœ
        print("=" * 60)
        print("ğŸ¯ è¯„ä¼°ç»“æœ:")
        print(f"   æ ·æœ¬æ•°é‡: {results['count']}")
        print(f"   CIDEråˆ†æ•°: {results['CIDEr']:.4f}")
        print(f"   åˆ†æ•°èŒƒå›´: [{min(results['scores']):.4f}, {max(results['scores']):.4f}]")
        print(f"   åˆ†æ•°æ ‡å‡†å·®: {np.std(results['scores']):.4f}")
        
        # 6. ä¿å­˜è¯¦ç»†ç»“æœ
        output_file = "cider_evaluation_results.json"
        detailed_results = {
            "checkpoint": checkpoint_path,
            "test_dataset": test_data_path,
            "results": results,
            "sample_predictions": [
                {
                    "index": i,
                    "prediction": pred,
                    "references": refs,
                    "cider_score": score
                }
                for i, (pred, refs, score) in enumerate(zip(
                    predictions[:5], references[:5], results['scores'][:5]
                ))
            ]
        }
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(detailed_results, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ“ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
        
        # 7. æ˜¾ç¤ºç¤ºä¾‹
        print("\n" + "=" * 60)
        print("ğŸ“‹ ç¤ºä¾‹é¢„æµ‹ç»“æœ:")
        for i in range(min(3, len(predictions))):
            print(f"\næ ·æœ¬ {i+1}:")
            print(f"é¢„æµ‹: {predictions[i]}")
            print(f"å‚è€ƒ: {references[i]}")
            print(f"CIDEr: {results['scores'][i]:.4f}")
        
        return results
        
    except Exception as e:
        print(f"âŒ è¯„ä¼°è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        return None


if __name__ == "__main__":
    results = main()
