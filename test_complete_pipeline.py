#!/usr/bin/env python3
"""
ç»¼åˆæµ‹è¯•ä¿®å¤åçš„è®­ç»ƒä»£ç 
"""

import os
os.environ["HF_ENDPOINT"] = "https://hf-mirror.com"
import sys
import torch
sys.path.append('/data1/wangzhiye/1a1a11/original')

from numeric_qwen2_5_vl import (
    NumericQwen2_5_VLConfig,
    NumericQwen2_5_VLProcessor,
    NumericQwen2_5_VLForConditionalGeneration
)
from training_config import create_model_and_processor

def test_complete_training_pipeline():
    print("=== ç»¼åˆæµ‹è¯•ä¿®å¤åçš„è®­ç»ƒç®¡é“ ===")
    
    # 1. æµ‹è¯•å¤„ç†å™¨
    print("\n1. æµ‹è¯•å¤„ç†å™¨...")
    processor = NumericQwen2_5_VLProcessor.from_pretrained('Qwen/Qwen2.5-VL-3B-Instruct')
    
    test_text = "äº§å“è¯„åˆ†ä¸º<num><8.5>åˆ†ï¼Œä»·æ ¼æ˜¯<num><299.99>å…ƒã€‚"
    result = processor(text=test_text, return_tensors="pt")
    
    print(f"åŸå§‹æ–‡æœ¬: {test_text}")
    print(f"å¤„ç†åçš„token: {processor.tokenizer.decode(result['input_ids'][0])}")
    print(f"æå–çš„æ•°å€¼: {result.get('numeric_values', 'æœªæ‰¾åˆ°')}")
    print(f"<num> token ID: {processor.num_token_id}")
    print(f"<num_pad> token ID: {processor.num_pad_token_id}")
    
    # 2. æµ‹è¯•æ¨¡å‹åˆ›å»º
    print("\n2. æµ‹è¯•æ¨¡å‹å’Œå¤„ç†å™¨åˆ›å»º...")
    try:
        model, proc = create_model_and_processor('Qwen/Qwen2.5-VL-3B-Instruct')
        print("âœ… æ¨¡å‹å’Œå¤„ç†å™¨åˆ›å»ºæˆåŠŸ")
        print(f"æ¨¡å‹é…ç½®ä¸­çš„ num_token_id: {getattr(model.config, 'num_token_id', 'None')}")
        print(f"æ¨¡å‹é…ç½®ä¸­çš„ num_pad_token_id: {getattr(model.config, 'num_pad_token_id', 'None')}")
    except Exception as e:
        print(f"âŒ æ¨¡å‹åˆ›å»ºå¤±è´¥: {e}")
        return False
    
    # 3. æµ‹è¯•å‰å‘ä¼ æ’­
    print("\n3. æµ‹è¯•å‰å‘ä¼ æ’­...")
    try:
        model.eval()
        with torch.no_grad():
            # å‡†å¤‡è¾“å…¥
            inputs = processor(text=test_text, return_tensors="pt")
            
            # å‰å‘ä¼ æ’­ï¼ˆæ˜¾å¼è®¾ç½®return_dict=Trueï¼‰
            outputs = model(**inputs, return_dict=True)
            
            print(f"âœ… å‰å‘ä¼ æ’­æˆåŠŸ")
            print(f"Logits shape: {outputs.logits.shape}")
            if hasattr(outputs, 'predicted_floats') and outputs.predicted_floats is not None:
                print(f"Predicted floats shape: {outputs.predicted_floats.shape}")
            else:
                print("âš ï¸  predicted_floats ä¸º None æˆ–ä¸å­˜åœ¨")
            
    except Exception as e:
        print(f"âŒ å‰å‘ä¼ æ’­å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    # 4. æµ‹è¯•æŸå¤±è®¡ç®—
    print("\n4. æµ‹è¯•æŸå¤±è®¡ç®—...")
    try:
        # åˆ›å»ºå‡æ ‡ç­¾
        input_ids = inputs['input_ids']
        labels = input_ids.clone()
        
        # æ·»åŠ æ•°å€¼ä¿¡æ¯
        inputs['labels'] = labels
        inputs['numeric_values'] = result['numeric_values']
        inputs['numeric_positions'] = result['numeric_positions']
        
        # è®¡ç®—æŸå¤±
        outputs = model(**inputs, return_dict=True)
        
        if outputs.loss is not None:
            print(f"âœ… æŸå¤±è®¡ç®—æˆåŠŸ: {outputs.loss.item():.4f}")
        else:
            print("âš ï¸  æ²¡æœ‰è¿”å›æŸå¤±å€¼")
            
    except Exception as e:
        print(f"âŒ æŸå¤±è®¡ç®—å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    print("\n=== æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼å¯ä»¥å¼€å§‹è®­ç»ƒ ===")
    return True

if __name__ == "__main__":
    success = test_complete_training_pipeline()
    if success:
        print("\nğŸ‰ è®­ç»ƒä»£ç å·²å‡†å¤‡å°±ç»ªï¼")
    else:
        print("\nâš ï¸  è¿˜æœ‰é—®é¢˜éœ€è¦è§£å†³")
